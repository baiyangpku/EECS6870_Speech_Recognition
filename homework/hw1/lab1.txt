
########################################################################
#   Lab 1: My First Front End
#   EECS E6870: Speech Recognition
#   Due: February 12, 2016 at 6pm
########################################################################

* Name:Yang Bai
* UNI: yb2356


########################################################################
#   Part 0
########################################################################

* Looking at how the performance of ASR systems have progressed
  over time, what is your best guess of when machine performance
  will reach human performance for unconstrained speech recognition?
  How do you feel about this?

-> At least decades of years. Unconstrained speech recognition is easy to be implemented on standard and fluent speech, but hard to recognize dialects and different accents for the same language.    


* Give some reasonable values for the first 3 formants on
  the mel scale for the vowel "I" (as in "bit") for a male and
  female speaker.  Do you see any obvious problems in using
  mel frequency spectrum (not cepstrum) features during
  recognition?  How might such problems be overcome?

->       F0       F1     F2     F3
MALE     138	  342    2322   3000
FEMALE   227      437    2761   3372
The formants of same vowels and words differs between women and men.
Same features may be categorized into different mel bins after using mel frequency spectrum.
Thus we need to operate a simple gender recognition before mel binning.


* In discussing window length in lecture 2, we talked about how
  short windows lead to good time resolution but poor frequency resolution,
  while long windows lead to the reverse.  One idea for addressing this problem
  is to compute cepstral coefficients using many different window lengths,
  and to concatenate all of these to make an extra wide feature vector.
  What is a possible problem with this scheme?

-> It is very inefficient. Much computation and little improvement. 
The extra wide feature vectors are highly correlated which provides limited information.


* Optional: in DTW, the distance between two samples grows linearly
  in the length of the samples.  For instance, the distance between two
  instances of the word "no" will generally be much smaller than the
  distance between two instances of the word "antidisestablishmentarianism".
  One idea proposed to correct for this effect is to divide the
  distance between two samples (given an alignment) by the number of
  arcs in that alignment.  From the perspective of a shortest path problem,
  this translates to looking for the path with the shortest *average*
  distance per arc, rather than the shortest *total* distance.  Is it
  possible to adapt the DP formula on the "Key Observation 1" slide
  (slide ~100 in lecture 2):

      d(S) = min_{S'->S} [d(S') + distance(S', S)]

  to work for this new scenario?  Why or why not?

-> It wonâ€™t work.If a word is very long, the mean distance will be much shorter.
This scenario give more tolerance on long words and may decrease the accuracy. 


########################################################################
#   Part 1
########################################################################

* Create the file "p1submit.dat" by running:

      lab1 --audio_file p1test.dat --feat_file p1submit.dat

  Electronically submit the files "front_end.C" and "p1submit.dat" by typing
  the following command (in the directory ~/e6870/lab1/):

      submit-e6870.py lab1 front_end.C p1submit.dat

  More generally, the usage of "submit-e6870.py" is as follows:

      submit-e6870.py <lab#> <file1> <file2> <file3> ...

  You can submit a file multiple times; later submissions
  will overwrite earlier ones.  Submissions will fail
  if the destination directory for you has not been created
  for the given <lab#>; contact us if this happens.


########################################################################
#   Part 2 (Optional)
########################################################################

* If you implemented a version of DTW other than the one we advocated,
  describe what version you did implement:

->https://en.wikipedia.org/wiki/Dynamic_time_warping
I used the pseudocode provided by wikipedia.

* Create a file named "p2.submit" by running:

      lab1_dtw --verbose true --template_file devtest.feats \
        --feat_file template.feats --feat_label_list devtest.labels > p2.submit

  Submit the files "lab1_dtw.C" and "p2.submit" like above:

      submit-e6870.py lab1 lab1_dtw.C p2.submit


########################################################################
#   Part 3
########################################################################

Look at the contents of lab1p3.log and extract the following
word accuracies:

* Accuracy for windowing alone:

->test: ac, train: ac
  Accuracy: 9.09% (1/11), Error rate: 90.91% (10/11)
test: ae, train: ae
  Accuracy: 18.18% (2/11), Error rate: 81.82% (9/11)
test: ag, train: ag
  Accuracy: 9.09% (1/11), Error rate: 90.91% (10/11)
test: ai, train: ai
  Accuracy: 18.18% (2/11), Error rate: 81.82% (9/11)
test: aj, train: aj
  Accuracy: 18.18% (2/11), Error rate: 81.82% (9/11)
test: al, train: al
  Accuracy: 36.36% (4/11), Error rate: 63.64% (7/11)
test: an, train: an
  Accuracy: 18.18% (2/11), Error rate: 81.82% (9/11)
test: aw, train: aw
  Accuracy: 18.18% (2/11), Error rate: 81.82% (9/11)
test: bd, train: bd
  Accuracy: 9.09% (1/11), Error rate: 90.91% (10/11)
test: bh, train: bh
  Accuracy: 36.36% (4/11), Error rate: 63.64% (7/11)
TOTAL: acc: 19.09% (21/110), ser: 80.91% (89/110)


* Accuracy for windowing+FFT alone:

->test: ac, train: ac
  Accuracy: 9.09% (1/11), Error rate: 90.91% (10/11)
test: ae, train: ae
  Accuracy: 18.18% (2/11), Error rate: 81.82% (9/11)
test: ag, train: ag
  Accuracy: 9.09% (1/11), Error rate: 90.91% (10/11)
test: ai, train: ai
  Accuracy: 18.18% (2/11), Error rate: 81.82% (9/11)
test: aj, train: aj
  Accuracy: 18.18% (2/11), Error rate: 81.82% (9/11)
test: al, train: al
  Accuracy: 36.36% (4/11), Error rate: 63.64% (7/11)
test: an, train: an
  Accuracy: 18.18% (2/11), Error rate: 81.82% (9/11)
test: aw, train: aw
  Accuracy: 18.18% (2/11), Error rate: 81.82% (9/11)
test: bd, train: bd
  Accuracy: 9.09% (1/11), Error rate: 90.91% (10/11)
test: bh, train: bh
  Accuracy: 36.36% (4/11), Error rate: 63.64% (7/11)
TOTAL: acc: 19.09% (21/110), ser: 80.91% (89/110)


* Optional: If the above two accuracies are identical, can you give
  an explanation of why this might be?

->


* Accuracy for window+FFT+mel-bin (w/o log):

->test: ac, train: ac
  Accuracy: 72.73% (8/11), Error rate: 27.27% (3/11)
test: ae, train: ae
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ag, train: ag
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ai, train: ai
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aj, train: aj
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
test: al, train: al
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: an, train: an
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aw, train: aw
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: bd, train: bd
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: bh, train: bh
  Accuracy: 72.73% (8/11), Error rate: 27.27% (3/11)
TOTAL: acc: 93.64% (103/110), ser: 6.36% (7/110)


* Accuracy for window+FFT+mel-bin (w/ log):

->test: ac, train: ac
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ae, train: ae
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ag, train: ag
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ai, train: ai
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aj, train: aj
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
test: al, train: al
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
test: an, train: an
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aw, train: aw
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
test: bd, train: bd
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
test: bh, train: bh
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
TOTAL: acc: 96.36% (106/110), ser: 3.64% (4/110)


* Accuracy for window+FFT+mel-bin+DCT:

->test: ac, train: ac
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ae, train: ae
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ag, train: ag
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ai, train: ai
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aj, train: aj
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: al, train: al
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: an, train: an
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aw, train: aw
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: bd, train: bd
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: bh, train: bh
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
TOTAL: acc: 100.00% (110/110), ser: 0.00% (0/110)


* Accuracy for window+FFT+mel-bin+DCT (w/o Hamming):

->test: ac, train: ac
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ae, train: ae
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ag, train: ag
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ai, train: ai
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aj, train: aj
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
test: al, train: al
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: an, train: an
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aw, train: aw
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: bd, train: bd
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: bh, train: bh
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
TOTAL: acc: 99.09% (109/110), ser: 0.91% (1/110)


* Accuracy for MFCC on speaker-dependent task:

->test: ac, train: ac
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ae, train: ae
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ag, train: ag
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ai, train: ai
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aj, train: aj
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: al, train: al
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: an, train: an
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aw, train: aw
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: bd, train: bd
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: bh, train: bh
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
TOTAL: acc: 100.00% (110/110), ser: 0.00% (0/110)


* Accuracy for MFCC on gender+dialect-dependent task:

->test: ac, train: ac
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ae, train: st
  Accuracy: 81.82% (9/11), Error rate: 18.18% (2/11)
test: ag, train: ag
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ai, train: nh
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aj, train: aj
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: al, train: al
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: an, train: an
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aw, train: if
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
test: bd, train: bd
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: bh, train: pe
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
TOTAL: acc: 96.36% (106/110), ser: 3.64% (4/110)


* Accuracy for MFCC on gender-dependent task:

->test: ac, train: ac
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: ae, train: pd
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
test: ag, train: br
  Accuracy: 54.55% (6/11), Error rate: 45.45% (5/11)
test: ai, train: rp
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aj, train: cr
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
test: al, train: dn
  Accuracy: 81.82% (9/11), Error rate: 18.18% (2/11)
test: an, train: ei
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: aw, train: gg
  Accuracy: 81.82% (9/11), Error rate: 18.18% (2/11)
test: bd, train: aw
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
test: bh, train: pe
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
TOTAL: acc: 88.18% (97/110), ser: 11.82% (13/110)



* Accuracy for MFCC on speaker independent task:

->test: ac, train: ae
  Accuracy: 63.64% (7/11), Error rate: 36.36% (4/11)
test: ae, train: pp
  Accuracy: 72.73% (8/11), Error rate: 27.27% (3/11)
test: ag, train: ca
  Accuracy: 81.82% (9/11), Error rate: 18.18% (2/11)
test: ai, train: rn
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
test: aj, train: cf
  Accuracy: 81.82% (9/11), Error rate: 18.18% (2/11)
test: al, train: dc
  Accuracy: 72.73% (8/11), Error rate: 27.27% (3/11)
test: an, train: fd
  Accuracy: 81.82% (9/11), Error rate: 18.18% (2/11)
test: aw, train: gg
  Accuracy: 81.82% (9/11), Error rate: 18.18% (2/11)
test: bd, train: an
  Accuracy: 100.00% (11/11), Error rate: 0.00% (0/11)
test: bh, train: nr
  Accuracy: 90.91% (10/11), Error rate: 9.09% (1/11)
TOTAL: acc: 81.82% (90/110), ser: 18.18% (20/110)
 

* What did you learn in this part?

-> The accuracy of MFCC varies when gender, dialect and speaker varies. 
The formants of the same vowel may be categorized into different mel bins
which leads to different accuracy.


* Why would dynamic time warping on the raw waveform take
  so much longer than these other runs?

-> On the raw waveform, the distances between different frames are almost the same. This algorithm will suffer worst case. And the outmost loop of raw waveform in DTW is very long, which makes the DTW run much longer.


########################################################################
#   Part 4 (Optional)
########################################################################

* Describe what you tried, and why:

->


* Create the files "p4small.out" and "p4large.out" as follows:

    cat si.10.list | b018t.run-set.py p018h1.run_dtw.sh %trn %tst > p4small.out
    cat si.100.list | b018t.run-set.py p018h1.run_dtw.sh %trn %tst > p4large.out

  Submit these files, all source files you modified, and the binary
  "lab1" into "lab1ec" (not "lab1" !!), e.g.:

      submit-e6870.py lab1ec p4small.out p4large.out lab1 front_end.C   etc.

  NOTE: we will be running your code with no extra parameters, so if
  you added any parameters, make sure their default values are set correctly!!!


########################################################################
#   Wrap Up
########################################################################

After filling in all of the fields in this file, submit this file
using the following command:

    submit-e6870.py lab1 lab1.txt

The timestamp on the last submission of this file (if you submit
multiple times) will be the one used to determine your official
submission time (e.g., for figuring out if you handed in the
assignment on time).

To verify whether your files were submitted correctly, you can
use the command:

    check-e6870.py lab1

This will list all of the files in your submission directory,
along with file sizes and submission times.  (Use the argument
"lab1ec" instead to check your Part 4 submissions.)


########################################################################
#
########################################################################


